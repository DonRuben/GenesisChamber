# Integration Guide — Connecting External APIs

## Image Generation

### Nano Banana Pro (fal.ai)
Primary image model for concept visualization.

```python
# API: fal-ai/nano-banana
# Endpoint: https://fal.ai/models/fal-ai/nano-banana
# Strengths: Fast, high quality, good with text in images
# Best for: Hero images, concept art, brand visuals

prompt_template = """
{concept_visual_direction}
Style: {art_style}
Mood: {emotional_tone}
Color palette: {brand_colors}
Composition: {layout_description}
Text overlay: {if_needed}
--
Professional advertising photography, 8K resolution,
cinematic lighting, editorial quality
"""
```

### Recraft V3 (fal.ai)
Best for brand-consistent, design-system outputs.

```python
# API: fal-ai/recraft-v3
# Strengths: Vector-quality, brand colors, consistent style
# Best for: Logo concepts, icons, brand system elements
# Styles: realistic_image, digital_illustration, vector_illustration
```

### Flux 2 Pro (fal.ai)
Best for photorealistic and editorial imagery.

```python
# API: fal-ai/flux-2-pro
# Strengths: Photorealism, complex scenes, human figures
# Best for: Lifestyle shots, product mockups, editorial
```

### Ideogram V3 (fal.ai)
Best for images with text and typography.

```python
# API: fal-ai/ideogram-v3
# Strengths: Text rendering, logos with text, poster designs
# Best for: Any concept that includes readable text
```

### Selection Logic
```python
def select_image_model(concept):
    if concept.requires_text_in_image:
        return "ideogram_v3"
    elif concept.is_brand_system:
        return "recraft_v3"
    elif concept.is_photorealistic:
        return "flux_2_pro"
    else:
        return "nano_banana_pro"  # default
```

## Video Generation

### Kling 3.0 (fal.ai)
```python
# API: fal-ai/kling-video/v2/master/text-to-video
# Duration: 5s or 10s
# Aspect: 16:9, 9:16, 1:1
# Best for: Dynamic brand videos, product demos
```

### Veo 3.1 (fal.ai)
```python
# API: google/veo-3.1
# Duration: 8s
# Best for: Cinematic quality, atmospheric, emotional
# Note: Generates audio too (generate_audio=true)
```

### Wan 2.6 (fal.ai)
```python
# API: fal-ai/wan-2.6
# Duration: 8s
# Best for: Artistic, stylized, experimental
```

### Image-to-Video Pipeline
```
1. Generate hero image (Nano Banana / Recraft / Flux)
2. Use image as first frame for video
3. Apply video model with motion prompt
4. Result: 5-10s video clip that matches the concept exactly
```

## Voice & Music (ElevenLabs)

### Text-to-Speech
```python
# Model: eleven_v3
# Use: Voice-over for video scripts, presentation narration
# Voices: Select based on brand voice requirements
# Integration: Direct API or MCP tool (generate_tts)
```

### Music Generation
```python
# Model: ElevenLabs Music
# Use: Background music for videos, presentations
# Integration: Direct API or MCP tool (generate_music)
# Prompt: Describe genre, mood, instruments, tempo
```

## Production Pipeline

### Per-Slide Production
For each slide in a presentation:

```
1. CONCEPT → Text description from simulation
2. IMAGE PROMPT → Auto-generated from concept visual direction
3. IMAGE → Generated via appropriate model
4. VIDEO PROMPT → Scene description with motion
5. VIDEO → Generated from image + motion prompt
6. VOICE → Script read by ElevenLabs
7. MUSIC → Background generated by ElevenLabs
8. ASSEMBLY → All assets combined in production package
```

### Per-Video Production
For each commercial video:

```
1. SCRIPT → Scene-by-scene from simulation output
2. PER SCENE:
   a. Generate hero frame (image)
   b. Generate motion video from frame
   c. Generate voice-over line
   d. Generate ambient sound/music
3. COMPILE → Scene list with all asset URLs
4. MANUAL STEP → Final video editing (user or HeyGen)
```

## API Key Management

```json
{
  "fal_ai": {
    "key": "FAL_KEY",
    "env_var": "FAL_KEY",
    "models": ["nano-banana", "recraft-v3", "flux-2-pro", "ideogram-v3",
               "kling-3.0", "veo-3.1", "wan-2.6"]
  },
  "openrouter": {
    "key": "OPENROUTER_API_KEY",
    "env_var": "OPENROUTER_API_KEY",
    "models": ["claude", "gpt", "gemini", "grok", "llama", "mistral"]
  },
  "elevenlabs": {
    "key": "ELEVENLABS_API_KEY",
    "env_var": "ELEVENLABS_API_KEY",
    "models": ["eleven_v3", "music"]
  }
}
```

## Error Handling

```python
# All API calls should:
# 1. Retry 3x with exponential backoff
# 2. Fall back to alternative model on failure
# 3. Log all prompts and responses for debugging
# 4. Cache results to avoid re-generation
# 5. Validate outputs before proceeding

FALLBACK_CHAIN = {
    "image": ["nano_banana", "recraft_v3", "flux_2_pro"],
    "video": ["kling_3.0", "veo_3.1", "wan_2.6"],
    "voice": ["eleven_v3"],
    "llm": ["claude_sonnet", "gpt_5.1", "gemini_3_pro"]
}
```
